Streaming Attention Unit: REVERSE+SCAN (camera-ready)
Constant-Memory, Length-Free O(1)/token Streaming Reasoning via Positive Random Features, Anytime-Valid E-Processes, and Reversible Certificates

Abstract
We mathematically specify, analyze, and operationalize the Streaming Attention Unit (SAU), a streaming estimator for decayed softmax attention that uses constant memory and constant per-token time. The method combines positive random features (PRF) to linearize the exponential kernel, exponentially weighted sufficient statistics with decay, optional fixed-rank value compression, query-only whitening for conditioning, anytime-valid e-processes under previsible adaptation for risk control, and reversible scan-checkable certificates for linear logic. We state assumptions, estimands, estimators, and stopping rules; prove unbiasedness (no whitening), consistency (with whitening), length-free r^{-1/2} error bounds uniform in time for gamma in (0,1), and time-uniform Type-I control via Ville's inequality; and bound finite-precision and clipping budgets. The design is fully auditable via a Merkle-chained record and a one-pass verifier.

0. Problem and Estimand
   Let d,d_v in N. For a stream (k_t,v_t) in R^d x R^{d_v}, temperature tau>0, decay gamma in (0,1], and query q in R^d define
   (1) A_t(q) = sum_{j=1}^t gamma^{t-j} exp(q^T k_j / tau) v_j
   (2) B_t(q) = sum_{j=1}^t gamma^{t-j} exp(q^T k_j / tau)
   (3) y_t(q) = A_t(q) / B_t(q)
   Goal: construct yhat_t(q) with state independent of t and O(1) time per token, with guarantees uniform in t. The estimator should be implementable as a single forward scan that maintains a fixed-size state, supports optional low-rank compression of values, and provides auditable risk and logic certificates.

1. Notation
   Vectors are columns; ||.|| is the Euclidean norm; ||.||*inf is the max norm. Inner products x^T y use standard Euclidean geometry. F_t is the canonical filtration generated by the process up to time t. "Predictable" and "previsible" both mean F*{t-1}-measurable. Machine epsilon u is IEEE-754 double unit roundoff. All logarithms are natural unless explicitly stated. For any scalar sequence {a_t}, EWM_alpha denotes an exponentially weighted moving statistic with decay parameter alpha in (0,1). For gamma in (0,1), the effective length of the decayed window is L_eff = 1/(1-gamma).

2. Assumptions
   A1 PRF randomness: W = {w_i}*{i=1}^r, with w_i i.i.d. N(0, I_d), drawn once at initialization, independent of the data stream and queries. Seeds for W are recorded and auditable.
   A2 Data regularity: E||k_t||^2 < infinity and E||v_t||^2 < infinity. For time-uniform concentration, either i.i.d. or alpha-mixing with sum_m alpha(m) < infinity. This controls long-run dependence in the decayed sums.
   A3 Clipping: PRF exponents are clipped to [-c, c] for a fixed c>0. The empirical clip rate rho_clip,t is logged in the audit record. The clip budget is tuned so that bias remains below the PRF variance term.
   A4 Decay: gamma in (0,1] is fixed. Length-free uniformity requires gamma in (0,1). For gamma=1 a finite horizon T is declared, or a denominator floor is introduced (Sec. 8).
   A5 Preconditioning: per-coordinate EWM2 (mean and variance) of phi are updated at ingest; whitening occurs only at query time to avoid bias in the streaming state.
   A6 Low rank (optional): U in R^{d_v x r_v} with U^T U = I*{r_v} is fixed, with r_v independent of t. If U is learned, its updates are made predictable with respect to F_{t-1}.
   A7 Risk mgf: there is a sub-exponential envelope (nu^2, b') such that mgf bounds hold for self-normalized coordinates, with valid lambda in (-1/b', 1/b'). A discrete mixture grid {lambda_k} is projected predictably to remain in-domain.
   A8 Regularization: lambda_star(t) >= 0 is predictable. It can be zero in the correctness path or positive in the stabilized path.
   A9 Finite precision: base arithmetic is IEEE-754 double with Kahan compensation on decayed GEMV updates; denominators are accumulated and read out in extended precision until division; optional per-row quantization applies only to R or H (never to s or denominators).
   A10 Auditing: each ingest or query emits a Merkle hash over digests of state fragments, risk logs, and certificate fields, enabling one-pass verification.

3. Positive Random Features (PRF)
   For x in R^d define a positive feature map phi(x) in R^r by
   (4) phi_i(x) = r^{-1/2} exp( w_i^T x / sqrt(tau) - ||x||^2 / (2 tau) ), i = 1..r
   Optionally pair features as (w, -w) to reduce variance while preserving positivity and unbiasedness. The scaling ensures that E||phi(x)||^2 is O(1) as r grows.

Theorem 3.1 (unbiased kernelization, no clipping).
E_W[ phi(q)^T phi(k) ] = exp( q^T k / tau ).
Sketch: With w ~ N(0, I_d), E[exp(w^T (q+k)/sqrt(tau))] = exp(||q+k||^2/(2 tau)). Multiplying by exp(-(||q||^2 + ||k||^2)/(2 tau)) yields exp(q^T k / tau). Averaging over r i.i.d. features produces an unbiased Monte Carlo estimate.

Proposition 3.2 (clipping bias).
There exist constants C1, C2 depending only on (c, tau) such that
(5) | E[phi_c(q)^T phi_c(k)] - exp(q^T k / tau) |
<= C1 exp(q^T k / tau) P(|G| > c) + C2 r^{-1/2} exp(|q^T k| / tau),
where Var(G) = ||(q+k)/sqrt(tau)||^2. Choose rho_clip in [0.1%, 1%] so that the first term is negligible relative to the r^{-1/2} Monte Carlo term. The audit record logs rho_clip to demonstrate budget compliance.

Variance note: Var(phi(q)^T phi(k)) = Theta( r^{-1} exp(2 q^T k / tau) ) under no clipping, with constants moderated by pairing and whitening.

4. Streaming Sufficient Statistics
   Let phi_t := phi(k_t). Maintain decayed sufficient statistics
   (6) R_t = gamma R_{t-1} + phi_t v_t^T in R^{r x d_v} [Kahan per row]
   (7) s_t = gamma s_{t-1} + phi_t in R^{r}
   When low-rank values are desired (fixed U),
   (8) H_t = gamma H_{t-1} + phi_t rhat_t^T in R^{r x r_v}, with rhat_t approx U^T v_t
   Updates (6)-(8) are O(r d_v) or O(r r_v) per step respectively. Kahan compensation reduces accumulation error in decayed sums and is logged.

5. Query, Whitening, Readout
   Per-coordinate ingest-time preconditioner:
   (9) mu_t = (1 - beta_mu) mu_{t-1} + beta_mu phi_t
   (10) sigma_t^2 = (1 - beta_sigma) sigma_{t-1}^2 + beta_sigma (phi_t - mu_t)^2 + epsilon 1
   Query-only whitening (predictable at time t):
   (11) phi_w(q) = diag( sigma_t^2 + epsilon )^{-1/2} phi(q)
   Denominator with predictable regularization:
   (12) den_t(q) = phi_w(q)^T s_t + lambda_star(t) (>= 0)
   Readouts:
   (13) yhat_t(q) = (phi_w(q)^T R_t) / den_t(q)
   (14) yhat_t^{low}(q) = U ( (phi_w(q)^T H_t) / den_t(q) )
   RJ half-split for diagnostics (Sec. 10):
   (15) yhat_t^{(j)}(q) = (phi_{w,I_j}(q)^T R_t^{(j)}) / (phi_{w,I_j}(q)^T s_t^{(j)} + lambda_star)
   (16) RJ_gap_t = || yhat_t - 0.5 ( yhat_t^{(1)} + yhat_t^{(2)} ) || / ( ||yhat_t|| + epsilon )

Whitening rationale: scaling coordinates by sigma_t stabilizes the denominator distribution and reduces condition numbers without biasing the streaming state, because whitening is applied at query time only. With stationary phi_t, the whitened estimator targets a whitened-kernel limit (Sec. 7).

6. Targets and Estimators
   Targets:
   (17) y_t(q) decayed softmax attention
   (18) y_t^{(w)}(q) whitened-kernel limit, defined by replacing phi with phi_w in the kernel identity
   Estimators:
   (19) yhat_t^{PRF}(q) = (phi(q)^T R_t) / (phi(q)^T s_t) correctness path (no whitening, lambda=0)
   (20) yhat_t^{(w)}(q) = (phi_w(q)^T R_t) / den_t(q) stabilized path
   (21) yhat_t^{low}(q) = U ( (phi_w(q)^T H_t) / den_t(q) ) stabilized, low-rank values
   The correctness path matches y_t(q) in expectation (no clipping) and concentrates with r^{-1/2}; the stabilized path targets y_t^{(w)}(q) and enjoys improved conditioning and denominator control.

7. Expectation Alignment, Concentration, Ratio
   Lemma 7.1 (alignment). E[phi(q)^T R_t] = A_t(q), and E[phi(q)^T s_t] = B_t(q), under no clipping and with independence from W.
   Lemma 7.2 (coordinate tails). For any fixed a, the scalar a^T (phi(x) - E phi(x)) is sub-exponential with parameters
   nu^2 <= K_nu e^{2c} ||a||^2 / r, b' <= K_b e^{c} ||a||_inf / sqrt(r).
   The constants K_nu, K_b depend only on tau and distributional bounds for k_t.
   Length-free uniformity for gamma in (0,1): the predictable quadratic variation (PQV) of compensated decayed sums is bounded by C/(1-gamma^2). Freedman's inequality yields, simultaneously for all t, with probability at least 1-delta,
   (22) || phi(q)^T R_t - E phi(q)^T R_t || <= K_A(gamma, c, tau) [ sqrt( (d_v + log(1/delta)) / r ) + (d_v + log(1/delta))/r ]
   (23) | phi(q)^T s_t - E phi(q)^T s_t | <= K_S(gamma, c, tau) [ sqrt( log(1/delta) / r ) + log(1/delta)/r ]
   Ratio perturbation bound. For vectors a,a_0 and scalars b,b_0 with beta = min{|b|,|b_0|} > 0,
   (24) || a/b - a_0/b_0 || <= ||a - a_0||/beta + ||a_0|| |b - b_0| / beta^2
   Theorem 7.3 (length-free approximation to y_t, gamma in (0,1)).
   Let beta_den(t,q) := min{ phi(q)^T s_t, E[phi(q)^T s_t] }. Under A1 - A4, with no whitening and lambda=0, with probability at least 1-delta simultaneously for all t >= 1,
   (25) || yhat_t^{PRF}(q) - y_t(q) ||
   <= (C1 / beta_den) sqrt( (d_v + log(1/delta)) / r )

* (C2 / beta_den^2) sqrt( log(1/delta) / r )
* E_clip + E_round
  where C1 = Theta(K_A), C2 = Theta(K_S), E_clip is the clipping bias from Prop. 3.2, and E_round is the finite-precision budget (Sec. 11). No term depends on t beyond logs via delta.
  Whitening consistency (stabilized target). If {phi_t} is ergodic with finite second moments, then for fixed q
  (26) yhat_t^{(w)}(q) -> y_t^{(w)}(q) in probability as r -> infinity, uniformly in t for gamma<1, with finite-r rate Theta(r^{-1/2}).
  Low-rank decomposition. For orthonormal U,
  (27) || yhat_t^{low} - y_t || <= || (I - U U^T) y_t || + || yhat_t - y_t || + err_ridge
  where err_ridge collects the effect of lambda_star and any numerical stabilization in the low-rank path.

Remark on gamma=1. When gamma=1, PQV grows with t and Freedman yields horizon-dependent bounds. In practice declare a horizon T, enable a positive beta_floor (Sec. 8), use RJ policy (Sec. 10), and report bounds on [1..T].

8. Denominator Regularization and Positivity
   Because phi_w >= 0 coordinatewise and s_t >= 0 coordinatewise, phi_w^T s_t >= 0. With predictable lambda_star(t) >= 0,
   (28) den_t(q) >= beta_eff := max{ beta_floor, lambda_star(t) } >= 0
   A fixed beta_floor > 0 is recommended for gamma=1 or when persistent RJ alarms indicate under-resolved variance. For gamma in (0,1) and sufficiently large r, lambda_star can be kept small or zero except during transient periods.

9. Anytime-Valid E-Processes (predictable, constructive)
   Self-normalized coordinates:
   (29) f_t = (1 - beta_f) f_{t-1} + beta_f phi_t
   (30) mu_t~ = (1 - beta_mu~) mu_{t-1}~ + beta_mu~ phi_t
   (31) v_t~ = (1 - beta_v~) v_{t-1}~ + beta_v~ (phi_t - mu_{t-1}~)^2
   (32) s_t* = (phi_t - mu_t~) ./ sqrt( v_t~ + epsilon ), Z_t = || s_t* ||^2
   Predictable mgf envelope:
   (33) psi(lambda) = nu^2 lambda^2 / (2 (1 - b' |lambda|)), for |lambda| < 1/b'
   Mixture process and previsible tilt:
   (34) log E_t(lambda) = sum_{tau <= t} [ lambda (Z_tau - bbar) - psi(lambda) ]
   (35) E_mix(t) = sum_k pi_k exp( log E_t(lambda_k) )
   (36) w_k(t) = pi_k exp( log E_t(lambda_k) ) / E_mix(t)
   (37) lambda_star(t) = sum_k w_k(t-1) lambda_k // predictable
   Domain projection (predictable). At time t-1 compute b'*hat from {s_tau*}*{tau <= t-1} and replace each lambda_k by sign(lambda_k) * min{ |lambda_k|, (1 - xi)/b'*hat } with fixed xi in (0,1).
   Theorem 9.1 (Ville). Each M_t(lambda) = exp( log E_t(lambda) ) is a nonnegative supermartingale; therefore E_mix(t) is a supermartingale. For any stopping time T and any alpha in (0,1),
   (38) P( sup*{t >= 1} E_mix(t) >= 1/alpha ) <= alpha
   Operational meaning: log margins m_t = log(1/alpha) - log E_mix(t) are valid at every time; negative margins indicate overrun of the risk budget and trigger deterministic policy actions (e.g., raising beta_floor or increasing r if allowed).

10. RJ Half-Split Diagnostic (operational policy)
    Construct two disjoint index sets I_1, I_2 over PRF coordinates (e.g., the first and second halves). Under weak cross-coordinate dependence, E[RJ_gap_t] = Theta(r^{-1/2}). Define
    (39) RJ_threshold_t(delta) = C_RJ sqrt( log( (t vee e)/delta ) / r )
    Policy: "yellow" if RJ_gap exceeds threshold on at least 3 of the last 10 steps; "red" if at least 5 of the last 10. On "red", deterministically raise beta_floor (and r if allowed) and log the action in the audit record. This policy couples a predictable diagnostic to predictable defenses without invalidating the e-process guarantees.

11. Finite-Precision and Quantization Budgets
    Kahan-compensated decayed sums S_t = sum_j gamma^{t-j} x_j satisfy
    (40) | fl(S_t) - S_t | <= u * C_K(gamma) * sum_j gamma^{t-j} |x_j| + O(u^2)
    with C_K(gamma) <= (1 + gamma) / (1 - gamma) for gamma in (0,1). For per-row q-bit quantization on R or H with scale s_row and row-2-norm bounded by L_row,
    (41) E_q,row <= 2^{-q} L_row per row GEMV
    Aggregate the rounding budget into (25) as
    (42) E_round <= u C_K(gamma) ( ||phi_w||_1 <|rows(R/H)|> + ||phi||_1 <|s|> ) + 2^{-q} sum_rows L_row
    Never quantize s or denominators, and keep denominator accumulation in extended precision until readout to avoid catastrophic cancellation.

12. Logic Certificates (robust Farkas, scan-checkable)
    Let A_core = { a_i^T x <= b_i }_{i=1}^m encode linear constraints and let the target be c_phi^T x <= d_phi. A numeric certificate consists of nonnegative multipliers alpha_i >= 0, a gain kappa >= 0, slack epsilon > 0, and tolerances (eta_c, eta_d) satisfying
    (43) || c_phi - kappa sum_i alpha_i a_i ||_inf <= eta_c
    (44) d_phi - kappa ( sum_i alpha_i b_i - epsilon ) >= -eta_d
    (45) kappa * epsilon > 10 (eta_c + eta_d)
    Then A_core implies the target. Verification is a one-pass O(1) memory check over streamed rows a_i,b_i and the stored certificate. The audit record includes hashes of certificate fields and tolerances.

13. Algorithms (O(1) state pseudocode)

Ingest(k_t, v_t):
phi_t <- phi(k_t) // PRF with clipping
R_t <- gamma R_{t-1} + GER_Kahan(phi_t, v_t^T)
s_t <- gamma s_{t-1} + KahanAdd(phi_t)
if low_rank:
rhat_t <- U^T v_t // predictable if U updated
H_t <- gamma H_{t-1} + GER_Kahan(phi_t, rhat_t^T)
mu_t, sigma_t^2 <- updates (9)-(10)
f_t, mu_t~, v_t~ <- (29)-(31); s_t*, Z_t
fit (nu^2_hat, bprime_hat) predictably from history
project lambda-grid using bprime_hat and xi
compute E_mix,w, lambda_star via (34)-(37)
emit audit record (Sec. 15)

Query(q):
phi_q <- phi(q)
phi_w <- diag(sigma_t^2 + epsilon)^{-1/2} phi_q
den <- phi_w^T s_t + lambda_star(t) // >= beta_eff
if low_rank:
z <- phi_w^T H_t
yhat <- U ( z / den )
else:
z <- phi_w^T R_t
yhat <- z / den
compute RJ_gap and apply policy (Sec. 10) if streaming
return yhat

All updates and readouts are O(1) in t for fixed r and r_v.

14. Complexity
    Ingest: O(r d) to form phi_t + O(r d_v) for GER into R_t (or O(r r_v) for H_t) + O(r) for statistics and risk updates.
    Query: O(r d) to form phi(q) + O(r d_v) GEMV (or O(r r_v)) + O(r) for denominators and diagnostics.
    State size: O(r d_v) or O(r r_v) plus O(r) for s_t and preconditioner, independent of t.

15. Audit Record (immutable, Merkle-chained)
    Per-step JSON (conceptual):
    { t,
    seeds: { PRF_seed, data_digest },
    tau, gamma, r, r_v,
    rho_clip, RJ_gap, beta_floor,
    lambda_grid_projected, lambda_star,
    nu2_hat, bprime_hat,
    digests: { rows(R_or_H), s }, kahan_residuals, saturation_events,
    certificate_fields_if_any,
    merkle_prev, merkle_curr
    }
    Verifier (one-pass):
    init merkle_prev = GENESIS
    for rec in stream:
    assert merkle( rec.body || merkle_prev ) == rec.merkle_curr
    assert log(1/alpha) - log E_mix(rec.t) >= 0 // Ville margin nonnegative
    check RJ policy thresholds and beta_floor actions
    if certificate present:
    recompute sums with streamed a_i,b_i; verify (43)-(45)
    merkle_prev <- rec.merkle_curr

16. Experimental Protocol (preregistered)
    DGP-A (correctness). k_t ~ N(0, I_d), v_t ~ N(0, I_{d_v}). Evaluate yhat^{PRF} (no whitening, lambda=0) vs exact y_t with multiple r. Metric RelErr_t(q) = ||yhat - y|| / (||y|| + epsilon). Hypothesis: E RelErr_t <= C / sqrt(r) uniformly in t for gamma in (0,1).
    DGP-B (low rank). v_t = U_* c_t with U_* orthonormal and c_t ~ N(0, I_{r_v}). Compare full vs low-rank readouts; measure geometric error ||(I - U U^T) y_t|| and PRF error separately.
    DGP-C (drift). K clusters with centers mu_k; phases cycle through classes. Track centroid accuracy and e-process margins m_t. Confirm that RJ policy elevates beta_floor during hard phases.
    Reporting. Provide CSVs for A/B/C with seeds, run.json, and the full audit stream (rho_clip, RJ, denom stats, Kahan residuals). Include ablations over gamma, c (clipping), lambda grids, and r_v.

17. Parameter Selection and Safety
    Feature count r. For target epsilon>0 and confidence 1-delta, choose approximately
    r ~= C0 ( r_v + log(1/delta) ) / epsilon^2
    with C0 depending on K_A, K_S, and conditioning. Increase r for larger d_v or tighter risk.
    Temperature tau. Start at tau ~= sqrt(d) and tune within x[0.7, 1.4] to balance kernel sharpness and variance.
    Decay gamma. Choose from desired L_eff = 1/(1-gamma). For length-free guarantees use gamma in (0,1); for gamma=1 declare horizon T and enable beta_floor.
    Regularization lambda. Maintain a small grid near the empirical median of raw denominators multiplied by {0, 0.5%, 1%, 2%}; project into (-1/b', 1/b') with slack xi, then average predictably to form lambda_star(t).
    Clipping c. Tune to keep rho_clip in [0.1%, 1%]. Larger c reduces bias but may stress floating-point; log both rho_clip and maximum exponent encountered.
    Risk envelope. Update (nu^2, b') predictably from the self-normalized stream. Keep lambda grid strictly in-domain with xi (e.g., xi=0.1).
    RJ and beta_floor. Set C_RJ to control false alarms at level delta over time using (39). On repeated alarms, raise beta_floor deterministically and log.

18. Threats to Validity and Mitigations
    Whitening bias. The correctness path (19) isolates the unbiased target y_t. The stabilized path targets y_t^{(w)}; both are reported with labels to avoid conflation.
    Clipping effects. Controlled via (5); rho_clip and c are logged to demonstrate that bias budgets remain subordinate to the r^{-1/2} term.
    Small denominators. Handled by lambda_star and beta_floor; RJ policy provides an operational signal. Predictability of these controls preserves e-process validity.
    Temporal dependence. With gamma<1, PQV is bounded; with gamma=1, declare horizon T and use time-local bounds and policy safeguards.
    Rank mismatch. Error decomposes via (27) into geometric, PRF, and ridge components; each term is measured separately in experiments.
    Numeric saturation. Kahan residuals and saturation events are logged; E_round is folded into (25) to keep guarantees explicit.

19. Reproducibility
    All randomness and hyperparameters are saved in run.json. Each step appends an audit record linked by a Merkle chain. The public verifier replays the stream in O(1) memory, checking digests, Ville margins, RJ policy adherence, and any logic certificates. Deterministic seeds reproduce W and therefore the entire PRF basis; changes to seeds are explicitly versioned.

20. Related Methodological Context
    Positive random features specialize random feature methods to the exponential kernel with strictly nonnegative coordinates, enabling ratio estimators that avoid cancellation. Decay gamma in (0,1) converts unbounded partial sums into processes with bounded PQV, activating length-free martingale concentration. E-processes generalize nonnegative supermartingales to provide time-uniform risk control under predictable adaptation. The combination yields streaming estimators with both algorithmic and statistical guarantees at O(1)/token cost.

21. Implementation Notes and FAQ
    Numerical stability. Perform PRF exponent arithmetic in double; subtract ||x||^2/(2 tau) before exp to reduce overflow risk; apply clipping c and log rho_clip. Use Kahan for all decayed accumulations and keep denominator in extended precision until division.
    Memory layout. Store R_t row-major contiguous with weights aligned; keep s_t contiguous; maintain mu_t, sigma_t^2 as contiguous vectors. This maximizes cache locality for phi_w^T R_t and phi_w^T s_t.
    Parallel queries. Multiple queries q can be batch-formed by reusing s_t and R_t; whitening uses the same sigma_t per coordinate and can be vectorized.
    Adaptive U (optional). If U is updated online (e.g., Oja), ensure predictability: update U only at the end of step t using information up to F_{t-1}, or freeze U for intervals and log epoch boundaries.
    Overflow guards. If exp arguments exceed safe ranges prior to clipping, fall back to log-sum-exp style stabilization at feature-construction time; this maintains positivity post-clipping.
    Determinism switches. Provide a flag to fix event order, enable compensated summation everywhere, and force deterministic lambda_star(t); this produces bit-stable runs for auditing.

22. Expanded Proof Sketches
    Unbiasedness (Thm 3.1). For any fixed q,k, with w ~ N(0,I_d),
    E exp( w^T (q+k)/sqrt(tau) ) = exp( ||q+k||^2 / (2 tau) ).
    Multiplying by exp( - (||q||^2 + ||k||^2) / (2 tau) ) yields exp( q^T k / tau ). Averaging across r i.i.d. features gives an unbiased Monte Carlo estimator with variance O(r^{-1}).
    Concentration (22)-(23). Write the decayed process X_t = sum_{j<=t} gamma^{t-j} xi_j where xi_j are centered, sub-exponential coordinates coming from a^T(phi(k_j)-E phi(k_j)). The PQV of the compensated version is bounded by C(gamma) sum_j gamma^{2(t-j)} <= C/(1-gamma^2). Apply Freedman's inequality with sub-exponential tail parameters (nu^2/r, b'/sqrt(r)) to obtain uniform-in-t bounds. A union bound across d_v coordinates yields the displayed dependence.
    Ratio bound (25). Combine alignment, concentration, and (24). The denominator lower bound beta_den controls division sensitivity; the clipping and rounding budgets enter additively.

23. Extended Low-Rank Analysis
    If v_t lies approximately in the span of U with residual e_t, then v_t = U U^T v_t + e_t. The estimator yhat_t^{low} uses U U^T v_t as a surrogate; the induced bias in the target is ||(I - U U^T) y_t||, and the estimator error decomposes as in (27). If U is learned, update it at predictable times and log the subspace drift; this preserves both auditability and statistical guarantees.

24. Full Pseudocode Extracts (ASCII)

struct State {
// Random features
Matrix<float> R; // r x d_v or r x r_v if low-rank
Vector<float> s; // r
// Preconditioner
Vector<float> mu; // r
Vector<float> sig2; // r
// Risk process
Vector<float> f, mu_tilde, v_tilde; // r each
double E_mix; // scalar e-process mixture
Vector<double> logE; // per-lambda accumulators
Vector<double> lambdas; Vector<double> pis;
double lambda_star; // predictable tilt
// Housekeeping
double gamma, tau; int r, r_v; bool low_rank;
Matrix<float> U; // d_v x r_v, if low_rank
double beta_floor; // denominator floor
double c_clip; // PRF clip
Seed prf_seed; // PRF seed
Hash merkle_prev;
}

Vector<float> PRF(const Vector<float>& x, const State& S) {
// returns phi(x) with clipping
Vector<float> phi(S.r);
for i in 1..S.r:
g = dot(S.W[i], x) / sqrt(S.tau) - 0.5 * norm2(x) / S.tau
g = clamp(g, -S.c_clip, S.c_clip)
phi[i] = exp(g) / sqrt(S.r)
return phi
}

void Ingest(State& S, const Vector<float>& k_t, const Vector<float>& v_t) {
phi_t = PRF(k_t, S)
S.R = S.gamma * S.R + GER_Kahan(phi_t, (S.low_rank ? (S.U^T * v_t) : v_t))
S.s = S.gamma * S.s + KahanAdd(phi_t)
// Preconditioner
S.mu = (1 - beta_mu) * S.mu + beta_mu * phi_t
S.sig2 = (1 - beta_sig)* S.sig2 + beta_sig * square(phi_t - S.mu) + eps
// Risk
S.f = (1 - beta_f) * S.f + beta_f * phi_t
S.mu_tilde = (1 - beta_mu_t) * S.mu_tilde + beta_mu_t * phi_t
S.v_tilde = (1 - beta_v_t) * S.v_tilde + beta_v_t * square(phi_t - S.mu_tilde)
s_star = (phi_t - S.mu_tilde) ./ sqrt(S.v_tilde + eps)
Z = norm2(s_star)
project_lambda_grid(S) // uses predictable bprime_hat
update_e_process_mixture(S, Z) // (34)-(37)
emit_audit_record(S) // Sec. 15
}

Vector<float> Query(State& S, const Vector<float>& q) {
phi_q = PRF(q, S)
phi_w = phi_q ./ sqrt(S.sig2 + eps)
den = dot(phi_w, S.s) + max(S.lambda_star, S.beta_floor)
z = transpose(phi_w) * S.R
if S.low_rank: return S.U * (z / den)
else : return (z / den)
}

25. Conclusion
    Under A1 - A10 and gamma in (0,1), REVERSE+SCAN achieves constant-memory, O(1)/token estimation of decayed softmax attention with length-free r^{-1/2} approximation error, constructive anytime-valid risk control, and scan-checkable logic certificates. The split between correctness (no whitening, no lambda) and stabilized estimators (whitening plus predictable lambda) provides both unbiasedness and operational robustness. Auditing and one-pass verification make the method suitable for high-assurance streaming deployments.

Appendix A. Length-Free Uniformity via Decay
For decayed compensated sums {M_t}, PQV <M>*infty <= C/(1 - gamma^2). Freedman's inequality implies, for centered sub-exponential increments with parameters (nu^2, b), that
P( sup*{t >= 1} | sum_{j <= t} M_j | >= u ) <= 2 exp( - u^2 / (2 (sigma^2 + b u)) )
with sigma^2 proportional to <M>_infty. Applying this to phi(q)^T R_t and phi(q)^T s_t yields (22)-(23) without explicit dependence on t.

Appendix B. Finite-Precision Budget
Kahan compensation yields
| fl(S_t) - S_t | <= u C_K(gamma) sum_j gamma^{t-j} |x_j| + O(u^2)
with C_K(gamma) <= (1 + gamma)/(1 - gamma). Per-row q-bit quantization on R or H contributes at most 2^{-q} ||row||_2 to the GEMV error; never quantize s or denominators. Combine these into E_round in (25).

Appendix C. RJ Thresholds
With weak dependence across halves,
Var( yhat - 0.5(yhat^{(1)} + yhat^{(2)}) ) = Theta(r^{-1})
Therefore
RJ_threshold_t(delta) = C_RJ sqrt( log( (t vee e)/delta ) / r )
controls time-uniform false alarms. Persistence rules (3/10 yellow, 5/10 red) trade sensitivity for specificity while keeping actions predictable.

Appendix D. Practical Defaults and Ranges
Defaults: r scaled by target epsilon; r_v chosen from value spectrum; tau in [0.7 sqrt(d), 1.4 sqrt(d)]; gamma in [0.90, 0.999] depending on desired L_eff; c set so rho_clip in [0.1%, 1%]; lambda grid near empirical denominator quantiles; xi=0.1 for domain slack; beta_floor=1e-6 to 1e-4 when gamma close to 1.

Appendix E. Worked Bound Constants (indicative)
For moderate clipping c in [5,8] and tau ~= sqrt(d), K_A and K_S can be taken on the order of exp(c) times smooth functions of gamma; this guides r via (25) for a target epsilon. Exact constants are logged per run through empirical estimates of nu^2 and b' and reported in the audit stream.
